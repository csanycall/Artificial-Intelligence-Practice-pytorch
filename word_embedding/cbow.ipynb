{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看数据文件目录  list datalab files\n",
    "!ls datalab/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看个人永久空间文件  list files in your permanent storage\n",
    "!ls /home/tianchi/myspace/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 查看当前kernel下已安装的包  list packages\n",
    "!pip list --format=columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class WordEmbCbow(nn.Module):\n",
    "    def __init__(self,nwords,emb_size):\n",
    "        super(WordEmbCbow,self).__init__()\n",
    "        self.emb=nn.Embedding(nwords,emb_size)\n",
    "        nn.init.uniform_(self.emb.weight,-0.25,0.25)\n",
    "        self.out=nn.Linear(emb_size,nwords)\n",
    "        nn.init.uniform_(self.out.weight,-0.25,0.25)\n",
    "    def forward(self,words):\n",
    "        emb=self.emb(words)\n",
    "        emb_sum=torch.sum(emb,dim=0)\n",
    "        emb_new=emb_sum.view(1,-1)\n",
    "        out=self.out(emb_new)\n",
    "        return out\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch=0,loss=9.4405\n",
      "epoch=0,loss=9.3011\n",
      "epoch=0,loss=9.1932\n",
      "epoch=0,loss=9.1243\n",
      "epoch=0,loss=8.9659\n",
      "epoch=0,loss=8.9011\n",
      "epoch=0,loss=8.7007\n",
      "epoch=0,loss=8.6057\n",
      "epoch=0,loss=8.5507\n",
      "epoch=0,loss=8.4961\n",
      "epoch=0,loss=8.4243\n",
      "epoch=0,loss=8.3348\n",
      "epoch=0,loss=8.1396\n",
      "epoch=0,loss=8.1230\n",
      "epoch=0,loss=8.0659\n",
      "epoch=0,loss=8.0511\n",
      "epoch=0,loss=8.0369\n",
      "epoch=0,loss=8.0303\n",
      "epoch=0,loss=7.9857\n",
      "epoch=0,loss=7.9765\n",
      "epoch=0,loss=7.9605\n",
      "epoch=0,loss=7.9326\n",
      "epoch=0,loss=7.9040\n",
      "epoch=0,loss=7.8868\n",
      "epoch=0,loss=7.8792\n",
      "epoch=0,loss=7.8311\n",
      "epoch=0,loss=7.8159\n",
      "epoch=0,loss=7.7865\n",
      "epoch=0,loss=7.7603\n",
      "epoch=0,loss=7.7496\n",
      "epoch=0,loss=7.7542\n",
      "epoch=0,loss=7.7554\n",
      "epoch=0,loss=7.7497\n",
      "epoch=0,loss=7.7212\n",
      "epoch=0,loss=7.7064\n",
      "epoch=0,loss=7.7138\n",
      "epoch=0,loss=7.7287\n",
      "epoch=0,loss=7.7260\n",
      "epoch=0,loss=7.7087\n",
      "epoch=0,loss=7.7033\n",
      "epoch=0,loss=7.6905\n"
     ]
    }
   ],
   "source": [
    "N=2\n",
    "EMB_SIZE=128\n",
    "w2i=defaultdict(lambda:len(w2i))\n",
    "UNK=w2i[\"<unk>\"]\n",
    "S = w2i[\"<s>\"]#开始和结束的标志\n",
    "label_location=\"out/label.txt\"\n",
    "embeddings_location=\"out/embedding.txt\"\n",
    "\n",
    "def read_dataset(filename):\n",
    "    with open(filename,\"r\") as f:\n",
    "        for line in f:\n",
    "            yield[w2i[i] for i in line.strip().split(\" \")]\n",
    "\n",
    "            \n",
    "train=list(read_dataset(\"Demo/DataSets/train.txt\"))\n",
    "w2i=defaultdict(lambda :UNK,w2i)\n",
    "dev=list(read_dataset(\"Demo/DataSets/test.txt\"))\n",
    "nwords=len(w2i)\n",
    "i2w={v:k for k,v in w2i.items()}\n",
    "\n",
    "with open(label_location,\"w\") as f:#将字典存储起来\n",
    "    for i in range(nwords):\n",
    "      f.write(i2w[i]+\"\\n\")#字典中的一个词占一行\n",
    "\n",
    "model=WordEmbCbow(nwords,EMB_SIZE)\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=0.01)\n",
    "def sent_loss(sent):\n",
    "    losses=[]\n",
    "    new_sent=[S]*N+sent+[S]*N\n",
    "    for i in range(N,len(sent)+N):\n",
    "            c=torch.tensor(new_sent[i-N:i]+new_sent[i+1:i+N+1])\n",
    "            t=torch.tensor([new_sent[i]])\n",
    "            logits=model(c)\n",
    "            loss=criterion(logits,t)\n",
    "            losses.append(loss)\n",
    "    return torch.stack(losses).sum()\n",
    "for epoch in range(100):\n",
    "    random.shuffle(train)\n",
    "    train_words,train_loss=0,0.0\n",
    "    for sent_id,sent in enumerate(train):\n",
    "        my_loss=sent_loss(sent)#总损失\n",
    "        train_loss+=my_loss.item()\n",
    "        train_words+=len(sent)\n",
    "        optimizer.zero_grad()\n",
    "        my_loss.backward()\n",
    "        optimizer.step()\n",
    "        if(sent_id%5==0):\n",
    "            print(\"epoch=%r,loss=%.4f\"%(epoch,train_loss/train_words))\n",
    "    print(\"epoch=%r,loss=%.4f\"%(epoch,train_loss/train_loss))\n",
    "    model.eval()\n",
    "    dev_words,dev_loss=0,0.0\n",
    "    for sent_id,sent in enumerate(dev):\n",
    "        my_loss=sent_loss(sent)#总损失\n",
    "        dev_loss+=my_loss.item()\n",
    "        dev_words+=len(sent)\n",
    "        optimizer.zero_grad()\n",
    "        my_loss.backward()\n",
    "        optimizer.step()\n",
    "        if(sent_id%500==0):\n",
    "            print(\"epoch=%r,loss=%.4f\"%(epoch,dev_loss/dev_words))\n",
    "    print(\"epoch=%r,loss=%.4f\"%(epoch,dev_loss/dev_loss))\n",
    "\n",
    "with open(embeddings_location, 'w') as embeddings_file:\n",
    "        W_w_np = model.emb.weight.data.numpy()\n",
    "        for i in range(nwords):#第几个单词\n",
    "            ith_embedding = '\\t'.join(map(str, W_w_np[i]))\n",
    "            embeddings_file.write(ith_embedding + '\\n')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
